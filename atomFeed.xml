<?xml version="1.0" encoding="utf-8"?>
	<feed xmlns="http://www.w3.org/2005/Atom">
	
	  <title>Ben</title>
	  <link href="https://wussell.github.io/atomFeed.xml"/>
	  <updated>2020-05-14T16:24:21-04:00</updated>
	  <author>
		<name>Ben Muthalaly</name>
	  </author>
	  <id>https://wussell.github.io/</id>
	
	  <entry>
		<title>4-4-20</title>
		<link href="https://wussell.github.io/4_4_20.html"/>
		<id>https://wussell.github.io/4_4_20.html</id>
		<updated>2020-05-14T16:24:21-04:00</updated>
	  </entry>

 	 <entry>
		<title>4-19-20</title>
		<link href="https://wussell.github.io/4_19_20.html"/>
		<id>https://wussell.github.io/4_19_20.html</id>
		<updated>2020-05-17T13:05:50-04:00</updated>
	  </entry>
	   
     <entry>
		<title>4-21-20</title>
		<link href="https://wussell.github.io/4_21_20.html"/>
		<id>https://wussell.github.io/4_21_20.html</id>
		<updated>2020-05-17T15:41:18-04:00</updated>
	  </entry>
 
		<entry>
		<title>4-22-20</title>
		<link href="https://wussell.github.io/4_22_20.html"/>
		<id>https://wussell.github.io/4_22_20.html</id>
		<updated>2020-05-18T12:24:15-04:00</updated>
	  </entry>
 
		<entry>
		<title>5-18-20test</title>
		<link href="https://wussell.github.io/5_18_20test"/>
		<id>https://wussell.github.io/5_18_20test</id>
		<updated>2020-05-19T16:18:13-04:00</updated>
	  	<content>
		  <![CDATA[
<p>
Atom feed

</p>  
<p>
Got command line input for the update function working with the scanln function in the fmt package. Learned a little about the Chomsky hierarchy and that you can't parse context free languages with regular expressions (?) while trying to investigate why stripping the tags from an html file was more difficult than I expected. Decided to change my approach from taking relevant parts out of the html file to creating an Atom entry and html file from a plain text file.

</p> 
<p>
To do:

</p>  
<p>
Automate git commit and push. Implement different functionality for updating an existing entry and for entirely new entries. Implement delete entry function. Add textual content of given file to entries.
</p>  
]]>

</content>
	 </entry>
	   
		<entry>
		<title>5-19-20test</title>
		<link href="https://wussell.github.io/5_19_20test"/>
		<id>https://wussell.github.io/5_19_20test</id>
		<updated>2020-05-19T16:40:34-04:00</updated>
		  <content>
		  <![CDATA[
		  <p>
will line breaks ever work

</p> 
 <p>
probably not. this is stupid

</p> 
<p> 
maybe it isn't working because you can't update a post in netnewswire

</p> 
 <p>
i hope not. that would be stupid</p> 
 ]]>
	</content>
	 </entry>
	   
		<entry>
		<title>5-19-20</title>
		<link href="https://wussell.github.io/5_19_20"/>
		<id>https://wussell.github.io/5_19_20</id>
		<updated>2020-05-19T16:56:33-04:00</updated>
		  <content>
		  <![CDATA[
		  <p>
Atom Feed:

</p> 
 <p>
Got it working with the new approach. Pretty simple overall, but I was still slow working out the minor bugs. But it's been the most productive day I had in a while. And this may be the first program I've written that makes my life slightly more convenient. Yay! Also, I don't think NetNewsWire updates unless an entry with a new id is added. I kept trying to add whitespace to the content on one post but nothing changed until I added a new post. Good to know.

</p> 
<p>
to do: 

</p> 
 <p>
Maybe reset the feed and build it back from the beginning so every post in the feed is formatted the same way. Change the keywords so that they're not normal words. Maybe add extra formatting to make each entry prettier? Automate git commit and push. Implement different functionality for updating an existing entry and for entirely new entries. Implement delete entry function.</p> 
 ]]>
	</content>
	 </entry>
	   
		<entry>
		<title>5-20-20</title>
		<link href="https://wussell.github.io/5_20_20"/>
		<id>https://wussell.github.io/5_20_20</id>
		<updated>2020-05-20T17:02:07-04:00</updated>
		  <content>
		  <![CDATA[
		  <p>
Huffman coding:

</p> 
 <p>
Finally got the bit sequence table working, with a lot of help. I don't think I would have been able to come up with the function I ended up using by myself. It would probably help to go through it again a few times to solidify the details. Now I'm working on the actual compressing of the file. It's fairly straightforward, but I do need to get a lot more comfortable with how Go stores and displays values, especially numbers in various bases. Hopefully I can finish the file compression tomorrow, and the decompression soon after.

</p> 
<p>
to do: 

</p> 
 <p>
File compression (including header and pseudo-eof), decompression, and testing.</p> 
 ]]>
	</content>
	 </entry>
	   
		<entry>
		<title>5-21-20</title>
		<link href="https://wussell.github.io/5_21_20"/>
		<id>https://wussell.github.io/5_21_20</id>
		<updated>2020-05-21T19:38:40-04:00</updated>
		  <content>
		  <![CDATA[
		  <p>
Huffman coding:

</p> 
 <p>
Finished the majority of the compression function today, which was pretty satisfying. Because the problem was easily comprehensible and the solution required no hidden knowledge, it was the kind of thing where there was no barrier between thinking about the solution and implementing the correct solution. Based on my limited observations so far, I think that's a common feature of enjoyable problems, at least for me. Things started moving along nicely once I changed my approach for compression from writing entire bit sequences at a time to the compressed data structure, to writing the sequences bit by bit. It was a small and obvious change, but encouraging because I've faced problems recently where I didn't recognize telltale signs to change my method. Also, it reminds me of the example in A Philosophy of Software Design about the word processor being much simpler and better to implement if the document was modified on a character by character basis instead of line by line. Maybe a pattern to keep in mind: it's simpler to work with smaller units of information.

</p> 
<p>
to do:

</p> 
 <p>
Finish compression function by figuring out how to generate pseudo-eof character and encode the tree in the compressed file. Implement decompression. Test.</p> 
 ]]>
	</content>
	 </entry>
	   
		<entry>
		<title>6-4-20</title>
		<link href="https://wussell.github.io/6_4_20"/>
		<id>https://wussell.github.io/6_4_20</id>
		<updated>2020-06-04T17:33:07-04:00</updated>
		  <content>
		  <![CDATA[
		  <p>
Huffman coding: 

</p> 
 <p>
Finished decompression a few days ago, but it decompressed into gibberish, so I've been working on testing. All the random tests I threw at the tree functions (creation, compression, decompression) seemed to pass just fine, so I thought the problem had to be with the function that parsed the compressed data. However, a more granular inspection revealed the output was different every time, and an even closer inspection revealed the tree was different every time, specifically which node each character was assigned to. I think the only source of that non-determinism is when I use a map to assign the character to a node, but I don't think that's what's causing the incorrect output. I might still try to find a way around that non-determinism just so debugging is easier, but I'm not sure.

</p> 
<p>
to do:

</p> 
 <p>
More testing.  </p> 
 ]]>
	</content>
	 </entry>
	   
		<entry>
		<title>6-9-20</title>
		<link href="https://wussell.github.io/6_9_20"/>
		<id>https://wussell.github.io/6_9_20</id>
		<updated>2020-06-09T17:50:12-04:00</updated>
		  <content>
		  <![CDATA[
		  <p>
Huffman coding

</p> 
 <p>
Finally finished it, I think. I figured out the function where the problem ended up being five days ago after doing the initial testing. It took me this long to fix it mostly due to a lack of focus and/or a lack of a systematic/logical thought process. I only needed to trace what the loop in the 'unhuff' function was doing to see that it was a problem with the location of some local variable declarations. After moving 3 lines of code around, the uncompressed data turned from gibberish into a perfect recreation of the original document. This was another point in favor of testing functions as I go, or at least moderately complex functions. Another thing that would be nice to take from this project is an improved naming convention. It might be beneficial to read through the pertinent sections of A Philosophy of Software Design and Elements of Closure again before going through and renaming the variables and functions and adding some documentation.

</p> 
<p>
Myers Diff

</p> 
 <p>
Not sure if I'm doing this next or not, but I started to try to build some intuition for how the algorithm works. Seems pretty cool, and I don't know much about graph theory or whatever so this seems like a nice place to start.</p> 
 ]]>
	</content>
	 </entry>
	   
		<entry>
		<title>7-6-20</title>
		<link href="https://wussell.github.io/7_6_20"/>
		<id>https://wussell.github.io/7_6_20</id>
		<updated>2020-07-06T16:54:01-04:00</updated>
		  <content>
		  <![CDATA[
		  <p>
photo sharing app

</p> 
 <p>
Perused the Wikipedia page for database normalization. It seems fairly straightforward and worth keeping in mind. So far, the basic design of the "app" consists of 3 main tables: users, albums, and photos, along with a table listing which users have permission to view each album. The album is the only organizational unit, so each user has one by default and all photos go into an album. I've only just started implementing the design into go, but so far I can't foresee any major complications.</p> 
 ]]>
	</content>
	 </entry>
	  
	</feed>